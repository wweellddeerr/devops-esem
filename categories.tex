\section{Categories and Concepts} \label{sec:categories_concepts}

In this section we detail and relate 
what we understand as being the core category
related to DevOps adoption (\cat{collaboration culture})  
with categories that either work as DevOps enabler or
are expected outcomes of a DevOps adoption process. 

\subsection{The Core Category: Collaboration Culture}

The \cat{collaboration culture} is the core category
for DevOps adoption. A \cat{collaboration culture} essentially aims to remove 
the silos between development and operations teams and activities.
As a result, operations tasks---like deployment, infrastructure provisioning 
management, and monitoring- should be considered as regular, day-to-day,
development activities. This leads to the first concept related to
this core category: {\bf operations tasks should be performed by
the development teams in a seamless way.}  

\begin{mq}
``\emph{A very important step that we took was to bring the deployment into day-to-day
development, no more waiting for a specific day of the week or month. We wanted
to do deployment all the time, even if in a first moment it were not in
production, a staging environment was enough. What we wanted was to embed
deployment into development. Of course, to carry out the deployment
continuously, we had to provide all the necessary infrastructure at the same
pace.}" (P14, IT Manager, Brazil)
\end{mq}

Without DevOps, a common scenario is an accelerated software development
without concerns about operations. At the end, when the development team has a
minimum viable software product, it is sent to the operations team for
publication. Knowing few things about the nature of the software and how it
was produced, the operations team has to create and configure an environment
and to publish the software. In this scenario, software delivery is typically
delayed and conflicts between teams manifest themselves. When a collaboration
culture is fomented, teams collaborate to perform the tasks from the first day
of software development. With the constant exercise of provisioning, management,
configuration and deployment, the software delivery becomes more natural,
reducing delays and, consequently, the conflicts between teams.

\begin{mq}
  ``\emph{We work in a very agile way, but we had a 15-day sprint where we focused on
producing software, so we produced in a very absurd speed, and at the time of
delivering what was produced, complications appeared. The job of setting up
the whole environment e make a manual deployment, this was not part of our
sprint, we focused only on coding the application. Then delivery was delayed,
having to deliver with delays of weeks, which was not good either for us or for
the clients.}" (P6, Developer, Portugal)
\end{mq}

As a result of constructing a \cat{collaboration culture}, the development
team no longer needs to stop their work waiting for the creation
of one application server, or for the execution of some database script, or for
the publication of a new version of the software in a staging environment.
Everyone needs to know the way this is done and, with the collaboration of the
operations team, this can be performed in a regular basis. If any task can be
performed by development team and there is trust between teams, this task is
incorporated into the development process in a natural way, manifesting the
second concept related to collaboration culture category: \textbf{software
development empowerment}.

\begin{mq}
``\emph{We had several people working on development, the amount of developers is
impressive. It was not feasible so many developers generating artifacts and
stopping their work to wait another completely separate team to publish. Or
needing a test environment and having to wait for the operations team to
provide it when possible. These activities have to be available to quickly
serve the development team. So, with DevOps we supply the need of freedom and
more power to execute some tasks which are intrinsically linked to their work.}"
(P5, Systems Engineer, Spain)
\end{mq}

A \cat{collaboration culture} requires  \textbf{product thinking}, in substitution to
\textbf{operations or development thinking}. The development team has to understand that
the software is a product that does not end after ``pushing'' the code to a 
project's repository and the operations team has to understand that the process does not
start when an artifact is received for publication. \textbf{Product thinking}
is the third concept related to \cat{collaboration culture} category.

\begin{mq}
``\emph{We changed the professional profile required in our contracting. We wanted to
contract people who could have a product vision. People who could see the
problem and think in the better solution to it. But not only think in a
software solution, also think about the moment when that application will be
published. We also bring together developers to reinforce that everyone
should think that way. Everyone has to think in the product and not only in
their code or in their infrastructure}" (P12, Cloud Engineer, United States)
\end{mq}

There should be a \textbf{facilitated communication} between teams. Ticketing
systems are cited as a typical and inappropriate means of communication
between development and operations teams. Face-to-face communication is the best
option, but considering that it is not always feasible, the continuous use of
tools like \emph{Slack} and \emph{Hip Chat} was cited as appropriate options.

\begin{mq}
``\emph{We also use this tool (Hip Chat) as a way to facilitate communication between
development and operations teams. The pace of work there is very accelerated,
it is not feasible to have a bureaucratic communication, so we use Hip Chat
a lot, everyone is always attentive, the answers are fast and we have a very
comprehensive control there. So, this gave us a lot of freedom to the development
activities, in case of any doubt, the operations staff is within reach of a
message.}" (P5, Systems Engineer, Spain)
\end{mq}

In case of problems at any point in the software life cycle, the responsibility
to check it is shared. The strategy of avoiding liability should be avoided.
The development team can not say that a given issue is a problem in infrastructure, then
it is responsibility of operations team. Or the opposite, the operations team
also can not say that a given failure was motivated by a problem in the application, then it is
responsibility of development team. A \textbf{blameless} context must exist.
The teams need to focus on solving problems, not on finding blame and
running away from responsibility. The context of \textbf{shared
responsibilities} involves not only solving problems, but also any other
responsibility inherent in the software product must be shared.
\textbf{Blameless} and \textbf{shared responsibilities} are the remaining
concepts of the core category.

\begin{mq}
``\emph{As a consequence of this continuous search for quality improvement, in an
advanced moment of the process, when we already had a good level of
collaboration, automation, and everything else, we identified a point of
amelioration. We realized that some people were afraid of making mistakes. Our
culture was not strong enough to make everyone feel comfortable to innovate and
experiment without fear of making mistakes. We made a great effort to spread
this idea that there are no blame for any problem that may occur. We take every possible
measure to avoid failures, but they
will happen, and we will only be able to solve a problem quickly without blame.}" (P8,
DevOps Engineer, Brazil)
\end{mq}

At first glance, considering the creation and strengthening of the \cat{collaboration
culture} as the most important step towards DevOps adoption seems somewhat obvious, but
the respondents cited some mistakes that they consider recurrent in not
prioritize this aspect in a DevOps adoption:

\begin{mq}``\emph{In a DevOps adoption, there is a very strong cultural issue that the teams
sometimes are not adapted. Related to this, one thing that bothers me a lot and
that I see happen a lot is people hitching DevOps exclusively by tooling or
automation.}" (P9, IT Manager, Brazil)
\end{mq}

Besides the core category (\cat{collaboration culture}), we identified
three other sets of categories: the categories that work as enablers
for DevOps adoption, the categories that a consequences of adopting
DevOps, and the categories that are both enablers and consequences.

\subsection{Enabler Categories}

In this section we details the categories that support the adoption of
DevOps practices. 
\subsubsection*{Automation} \label{ssec:automation}

Automation was the category with the higher number of related concepts. This
occurs because manual proceedings are considered as strong candidates to
propitiate the formation of a silo, hindering the construction
of a \cat{collaboration culture}. If a task is manual, one people, or one
team will be responsible to execute it. Although transparency and sharing can
be used to ensure collaboration even in manual tasks, with automation the
points where silos may arise are minimized.

\begin{mq}
``\emph{When a developer needed to build a new application, the previous workflow demanded her
to create a ticket to the operations teams, which should then manually evaluate and solve
the requested issue. This task could take a lot of time and there was no
visibility between teams about what was being done (\ldots). Today, those silos do not exist
anymore within the company, in particular because it is not necessary to execute all these tasks manually,
everything has been automated.}" (P12, Cloud Engineer, United States)
\end{mq}

In addition to contribute to \cat{transparency}, \cat{automation} is also considered
important to ensure \emph{reproducibility} of tasks, reducing rework and risk of
human failure. Consequently, \cat{automation} increases the confidence
between teams, which is an important aspect of the \cat{collaboration culture}.

\begin{mq}
``\emph{Before we adopted DevOps, there was a lot of manual work. For example, if you
needed to create a database schema, it was a manual process; if you needed to create a
database server, it was a manual process; if you needed to create one more EC2 instance,
such a process was also manual. This manual work was time consuming and often caused errors and
rework.}" (P1, DevOps Developer, Ireland)
\end{mq}

\begin{mq}
``\emph{Our main motivation to adopt DevOps was basically reduce rework. Almost every
week, we had to basically make new servers and start them manually, which was
very time-consuming.}" (P4, Computer Technician, Brazil)
\end{mq}

The eight concepts of automation category will be detailed next.
In all interviews we extracted explanations about \textbf{deployment
automation} (1), as part of DevOps adoption. Software delivery is the clearest
manifestation of value delivery in software development. In case of problems
in deployment, the expectation of delivering value to business can quickly
generate conflicts and manifest the existence of silos. As previously discussed,
automation typically increase agility and reliability of tasks. Some other
concepts of automation go exactly around deployment automation. To
effectively generate value to business, the mere quickly and successfully
deployment is not sufficient. The delivered software needs to have quality.
Therefore, quality checks needs to be automated so they can be part of the
deployment pipeline, is the case of \textbf{test automation} (2). In order
that the deployment can occur in an automated way, the environment where the
application will run needs to be available. So, \textbf{infrastructure
provisioning automation} (3) is embedded in the process. Beyond being available,
the environment needs to be properly configured, including the amount of memory and CPU,
libraries versions, and database structure. If the configuration of some of these concerns
has not been automated, the deployment actitivy can go wrong. Therefore,
the \textbf{infrastructure management automation} (4) is another
concept of the \cat{automation} category.

Modern software is built around services. Microservices  was commonly cited
as one aspect of DevOps adoption. To Fowler and Lewis
\cite{martinfowler2014microservices}, in the
microservice architectural style, services need to be independently deployable
by fully automated deployment machinery. We call this part of microservices
characteristics of \textbf{autonomous services} (5). \textbf{Containerization}
(6) is also metioned as a way to automate the provisioning of containers that are the
environment where these autonomous services will execute.
\textbf{Monitoring automation} (7) and \textbf{recovery automation} (8) are the
remaining concepts. The first refers to the ability to monitor the
applications and infrastructure without human intervention. One classic example
is the automated sending of alerts (SMS, Slack/Hip Chat messages, or even
cellphone calls) in case of incidents. And the second is related to the ability
to replace a component that is not working or
roll back a failed deployment without human intervention.


\subsubsection{Continuous Measurement}
Continuous measurement has two facets in a DevOps adoption process: it can work
as an enabler or as an outcome.

As an enabler, perform regularly the activities of measurement and share this
responsibility contributes to avoid this typical silo and reinforce the
collaboration culture, because it is a typical responsibility of the operations
team.

\begin{mq}
``\emph{Before, we had only sporadic looks to zabbix to check if everything was OK.
At most someone would stop to look memory and CPU consumption. To maintain the
high performance we have expanded this view of metrics collection so that it
became part of the software product. We pass to collect metrics continuously
and with shared responsibilities. For example, if an overflow occurred in the
number of database connections, everyone received an alert and had
responsibility for seeking solutions to that problem, it is a good example of
metrics that everyone started to be more attentive, not only the operations
area}" (P3, DevOps Developer, Ireland)
\end{mq}

As an outcome, continuously collect metrics from applications and
infrastructure is a required consequence of DevOps adoption. It occurs because
the resultant agility increases the risk of something going wrong. The team
should be able to react quickly in case of problems, and the continuous
measurement allows it to be proactive and resilient.

\begin{mq}
``\emph{
With DevOps we can do deployment all the time and, consequently, there was
the need of greater control of what was happening. So, we used grafana and
prometheus to follow everything that is happening in the infrastructure and in
the applications. We have a complete dashboard in real time, we extract reports
an, when something goes wrong, we are the first to know}" (P10, Network
Administrator, Brazil)
\end{mq}

Continuous monitoring involves \textbf{application log monitoring} (1), an
intuitive concept which corresponds to the use of the log produced by
applications and infrastructure as data source. The concept of
\textbf{continuous infrastructure monitoring} (2) indicates that the monitoring
is not performed by a specific person or team in a specific moment. The
responsibility to monitor the infrastructure is shared and it is executed in
day by day. \textbf{Continuous application measurement} (3), in turn, refers to
the instrumentation to provide metrics that are used to evaluate aspects and
often direct evolutions or business decisions. All these monitoring/measurement
can occur in an automated way, the \textbf{monitoring automation} already been
detailed in subsection \ref{ssec:automation}.

\subsection{Quality Assurance}

In the same way as continuous measurement, quality assurance is a category that
can work both as enabler and as outcome. As enabler because more quality
generates more confidence between teams generating a virtuous cycle of
collaboration between them. And as outcome the principle is that is not
feasible create a scenario of continuous delivery of software without control
about the quality of the products and its production processes.

Respondents pointed to the need for sophisticated control of which code should
be part of deliverables that are continuously delivered. Git Flow was
recurrently cited as suitable \textbf{code branching} (1) model, the first
concept of quality assurance.

In subsection \label{ssec:automation} we explore the automation face of
microservices and testing. These elements has also an quality assurance face.
Another characteristic of microservices is the need for small services focusing
in doing one thing well. These small services are more easy to scale and
structure, which manifest a quality assurance concept: \textbf{cohesive
services} (2). And about testing, the another face is \textbf{continuous
testing} (3). To ensure quality in software products, the obtained view is that
the tests and another quality checks can occur continuously. Continuous testing
is considered challenging without automation, and this reinforces the need of
the testing in an automated way.

Another two concepts cited as part of quality assurance in DevOps adoption are
the \textbf{source code static analysis} (4) to compute quality metrics in
source code of applications and the \textbf{parity between environments} to
reinforce transparency and collaboration during software development.

\subsection{Sharing}

The sharing category represents the grouping of concepts emerged from recurrent
relates of regular events of sharing. Trainings, tech talks, committees
lectures, and round tables are examples of these sharing events. The creation
of channels in communication tools are another pattern of stories about sharing
as part of DevOps adoption. According with the content of what is shared, we
have identified three concepts:

\begin{itemize}
\item Activities sharing, where the focus is on sharing how simple tasks were
performed. Communication tools, committees and round tables are the common
forum of the sharing of this type of content.
\item Knowledge sharing: the professionals interviewed mention a wide range of
skills they need to acquire during the adoption of DevOps. So, they cite
structured events of sharing to smooth the learning curve of both technical and
cultural knowledge.
\item Process sharing: here, the focus is on sharing whole work processes. The
content is more comprehensive than in sharing activities. Tech talks and
lectures are the common forum of process sharing.
\end{itemize}

These sharing concepts contribute with the collaboration culture. For example,
all team members gain a best insight about the entire software production
process, with more sense of shared responsibilities. A shared vocabulary also
emerged from sharing and this facilitates communication.

\subsection{Transparency}

Transparency contains concepts that are also commonly used to develop the
collaboration culture. The use of \textbf{infrastructure as code} was
recurrently cited as a mean of everyone knows how the execution environment of
an application is provided and managed. Bellow, we present an interview
transcript part which sums up this concept well:

\begin{mq}
``\emph{
So, here we adopted this type of strategy that is the infrastructure as code,
consequently we have the versioning of our entire infrastructure in a common
language, in such a way that any person, a developer, an architect, the
operations guy of even the manager, he looks and is able to describe that the
configuration of application x is y. So, it aggregates too much value for us
exactly with more transparency}" (P12, Cloud Engineer, United States)
\end{mq}

In previous section, we presented the concepts related to sharing category. In
transparency, exists the concept of \textbf{sharing on a regular basis}, that
is correspondent to the existence of regularity in the realization of the
sharing events. The sharing must to be embedded in the process of software
development to contribute effectively to transparency.

As will be better detailed in the concept of continuous integration of agility
category, a common way to integrate all tasks is a pipeline. Here, exists the
concept of \textbf{shared pipelines} which indicates that the code of pipelines
must be accessible to everyone, in order to foment the transparency.

\begin{mq}
``\emph{Today we have full code opening. The code of how the infrastructure is
made is open to developers and the sysadmins need to know some aspects of how 
the application code is built. The code of our pipelines is accessible for
everyone in the company to know how activities are automated}" (P13, Technology
Manager, Brazil)
\end{mq}

\subsection{Agility}

Agility is an well explored capability provided by DevOps adoption. With more
collaboration between teams, \textbf{continuous integration} with execution of
multidisciplinary pipelines is possible and it is an agility related concept
frequently explored by practitioners. These pipelines may contain
infrastructure provisioning, automated regression testing, code analysis,
automated deployment and any other task that the team consider important to
execute continuously.

These multidisciplinary pipelines provided in continuous integration naturally
enable the manifestation of two other agility concepts: \textbf{continuous
infrastructure provisioning} and \textbf{continuous deployment}. The latter is
one of the most recurrent concepts identified in the interview analysis. Before
DevOps, deployment was seen as a major event with high risk of downtime and
failure involved. After DevOps, the sensation of risk in deployment decreases
and this activity becomes more natural and frequent. Some practitioners claim
to perform dozens of deployments daily.

\subsection{Resilience}
Another category that appears as outcome of DevOps adoption is resilience. The
infrastructure has the capability of \textbf{auto scaling}, allocating more or
less resources to applications that increase or decrease in demand,
respectively.

Another concept of resilience category is \textbf{recovery automation} that is
the capability of applications and infrastructure to recovery itself in case of
some problem. There are two typical cases of recovery automation: (1) in cases
of some instability in the execution environment of an application (a
container, for example) occurs an auto restart of that environment; and (2) in
cases of new version deployment, if the new version does not work properly, the
previous one is automatic restored. This auto restore of previous version
allows that downtimes does not occur due to errors in specific versions, which
is the concept of \textbf{zero down-time}, the last one of resilience category.
