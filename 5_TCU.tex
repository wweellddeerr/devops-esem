\section{Application of The Model} \label{sec:tcu}

The TCU is responsible for the accounting, financial, budget, performance, and property
oversight of federal institutions and entities of the country. Currently, there are 2500
professionals working at the TCU, of which approximately 300 work directly on either
software development or operations. The source code repository at the TCU hosts more then 200 software projects, totaling
over 4 million lines of code.
Before the application of our model, the TCU had produced some w.r.t deployment
automation results and the focus was being directed to the tooling issue. Considering this
incomplete perspective of DevOps, the conflicts between development and operations
teams continued. That is, the mere advance in implanting ``DevOps tools'' simply
changed the points of conflict, but they persisted.

After the presentation of our  model in a series of lectures, development and
operations teams changed their focus to build a \cc. This
change was only possible due to the engagement and sponsorship of the IT
managers. Looking to the concepts within the \cc category, the first practical
action at the TCU was to facilitate communication between teams. The use of tickets
was then abolished. The problems had to be solved in a collaborative way, preferably
face to face.
Looking to enablers, the TCU is applying \cat{sharing and transparency} concepts.
The role of internal tech talks and committees to disseminate that collaboration
culture and related concepts is being reinforced.
When a new infrastructure had to be provided and configured, the current guideline is
that there must be a kind of \emph{pair programming} between developers and infrastructure
members. All application related tasks must be executed in a collaborative
way. Naturally, the professionals noticed that automation would facilitate the
operationalization of that collaboration. For this reason, the infrastructure provisioning
and management was automated.

The TCU also uses continuous measurement and quality assurance concepts as
enablers of its DevOps adoption. The applications started to be continuously
tested and measured. The tests were automated and included in the pipelines.
Verification of test coverage and quality code also became part of the pipeline.
This increased the confidence between teams. The TCU started
to explore the potential of DevOps tools, like recovery automation, zero
down-time, and auto scaling. The deployment has also been automated.
It is important to note that, before DevOps, deployment activities were historically a controversial point at the TCU.
Several conflicts occurred over time. Rigid procedures were created to try to
avoid problems. These ``rigid procedures'' often led to periods of months
without any software delivery. The more collaborative scenario, with a strong appeal in automation and quality,
created by following an appropriate path in adopting DevOps, enabled the deployment activities to become
a lightweight task at the TCU. Continuous deployment became a reality and, currently, several deployments
occur as regular activities of the development teams at the TCU.

Since the TCU is a government institution, some advances in DevOps adoption still comes up
against regulatory issues. For example, there are internal regulations that
establish that only the operations sector is responsible for issues related to
application infrastructure, contrasting with shared responsibilities that are
part of the \cc. Nevertheless, our model enabled the TCU to adopt DevOps in a more
sustainable way. Knowing the role
of each DevOps element in the adoption was fundamental for the TCU to avoid points
of failure and to build a collaborative environment that supports the
exploration of DevOps benefits.
